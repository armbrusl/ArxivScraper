{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import arxiv\n",
    "import re\n",
    "import os\n",
    "from os.path import exists\n",
    "\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "matplotlib.use('Qt5Agg')\n",
    "from pyvis.network import Network\n",
    "\n",
    "from PyPDF2 import PdfReader\n",
    "from refextract import extract_references_from_file\n",
    "\n",
    "client = arxiv.Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_extend(matrix):\n",
    "    flat_list = []\n",
    "    for row in matrix:\n",
    "        flat_list.extend(row)\n",
    "    return flat_list\n",
    "\n",
    "def splitAuthornames(names):\n",
    "    newNames = []\n",
    "    for name in names:\n",
    "        nameSeparated = name.split()\n",
    "        newname = nameSeparated.pop(1)\n",
    "        newNames.append(newname)\n",
    "\n",
    "    return ', '.join(newNames[:3])\n",
    "\n",
    "def check_file(fullfile):\n",
    "    with open(fullfile, 'rb') as f:\n",
    "        try:\n",
    "            pdf = PdfReader(f)\n",
    "            info = pdf.metadata\n",
    "            if info:\n",
    "                return True\n",
    "            else:\n",
    "                return False\n",
    "        except Exception as e:\n",
    "            return False\n",
    "\n",
    "def SearchArxiv(queries, nresults, cutoffDate):\n",
    "    all_data = []\n",
    "    names_list = []\n",
    "    title_list = []\n",
    "    references = []\n",
    "    counter = 0\n",
    "    for query in queries:\n",
    "\n",
    "        search = arxiv.Search(\n",
    "            query = query,\n",
    "            max_results = int(nresults / len(queries)),\n",
    "            sort_by = arxiv.SortCriterion.Relevance,\n",
    "            sort_order = arxiv.SortOrder.Descending\n",
    "        )\n",
    "        \n",
    "        results = client.results(search)\n",
    "\n",
    "        for result in results:\n",
    "            \n",
    "            temp = [\"\",\"\",\"\",\"\",\"\",\"\"]\n",
    "            names = re.findall(r\"'(.*?)'\", str(result.authors))\n",
    "            \n",
    "            #temp[0] = splitAuthornames(names)\n",
    "            temp[0] = names\n",
    "            temp[1] = result.title\n",
    "            temp[2] = result.published.date()\n",
    "            temp[3] = result.summary\n",
    "            temp[4] = result.pdf_url\n",
    "            temp[5] = query\n",
    "\n",
    "            if(int(str(temp[2])[:4]) > cutoffDate and title_list.count(temp[1]) <= 0):\n",
    "                \n",
    "                filename = \"papers/\" + \"\".join(x for x in temp[1] if x.isalnum() or x == \" \" or x== \"-\") + \".pdf\"\n",
    "                \n",
    "                if(exists(filename) == False):\n",
    "                    result.download_pdf(filename=filename)\n",
    "                \n",
    "                    if check_file(filename):\n",
    "                                            \n",
    "                        title_list.append(temp[1])\n",
    "                        all_data.append(temp)\n",
    "                        names_list.append(names)\n",
    "                        references.append(extract_references_from_file(filename))\n",
    "                        \n",
    "                        print(\"Saved \", str(counter) + \" : \", temp[1])\n",
    "                        counter += 1\n",
    "                    else:\n",
    "                        print(\"Corrupted File Deleted\")\n",
    "                        os.remove(filename)\n",
    "                \n",
    "                else:\n",
    "                    print(\"File already exists - no download - :\" + \"Saved \", str(counter) + \" : \", temp[1])                  \n",
    "                    title_list.append(temp[1])\n",
    "                    all_data.append(temp)\n",
    "                    names_list.append(names)\n",
    "                    references.append(extract_references_from_file(filename))\n",
    "                    counter += 1\n",
    "                        \n",
    "                \n",
    "                \n",
    "    return all_data, names_list, title_list, references\n",
    "\n",
    "def createAuthorNetwork(names_list, title_list, df, cutoffDate, wf):\n",
    "\n",
    "    # Create a graph\n",
    "    G = nx.Graph()\n",
    "\n",
    "    # Add edges between names within the same list\n",
    "    \n",
    "    flattened_list = flatten_extend(names_list)\n",
    "    for names in names_list:\n",
    "        c = 0\n",
    "        for name in names:\n",
    "            count = flattened_list.count(name)\n",
    "            if(G.has_node(name) == False):\n",
    "                if(c==0): # First author\n",
    "                    G.add_node(name, size= 5 + count**2, color='red', title = str(count), hover = str(count), label=name)\n",
    "                    c += 1\n",
    "                else:\n",
    "                    if(c == 0):\n",
    "                        G.add_node(name, size= 5 + count**2, color='red', title = str(count), hover = str(count), label=name)\n",
    "                    else:\n",
    "                        G.add_node(name, size= 5 + count**2, color='Blue', title = str(count), hover = str(count), label=name)\n",
    "    \n",
    "    for names, title_, PublishDate in zip(names_list, title_list, list(df.Date)):\n",
    "        weighingFactor = ((int(str(PublishDate)[:4]) - cutoffDate + 1)**wf) / 2\n",
    "        edgeLabel = str(PublishDate) + \" : \" + title_\n",
    "        \n",
    "        for i in range(len(names) - 1):\n",
    "\n",
    "            if(G.has_edge(names[i], names[i + 1]) == False):\n",
    "\n",
    "                G.add_edge(names[i],names[i + 1], color='black', weight=weighingFactor, hover= edgeLabel, title = edgeLabel)  # Connect names in the list\n",
    "            else: # adds to the title if the authors shar multiple papers\n",
    "\n",
    "                oldTitle = G.edges[names[i],names[i + 1]]['title']\n",
    "                oldweight = G.edges[names[i],names[i + 1]]['weight']\n",
    "                new_label = oldTitle + \" -|- \" + edgeLabel\n",
    "                new_weight = (oldweight + weighingFactor)/2\n",
    "                G.edges[names[i], names[i + 1]]['title'] = new_label\n",
    "                G.edges[names[i], names[i + 1]]['hover'] = new_label\n",
    "                G.edges[names[i], names[i + 1]]['weight'] = new_weight\n",
    "                \n",
    "        G.add_edge(names[0], names[len(names) - 1], color='black', weight=weighingFactor, hover=edgeLabel, title=edgeLabel)\n",
    "\n",
    "    net = Network(width = \"1920px\", height = \"1080px\", notebook = True, cdn_resources='local', directed=False)\n",
    "    net.from_nx(G)\n",
    "    \n",
    "    net.toggle_physics(True)\n",
    "    #net.show_buttons(filter_=['physics'])\n",
    "    net.save_graph(\"Network.html\")   \n",
    "    \n",
    "def createDateHistogram(dates):\n",
    "\n",
    "    # Create a histogram of dates\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.hist(dates, bins=60, edgecolor='black')  # Adjust the number of bins as needed\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title('Histogram of Dates')\n",
    "    plt.xticks(rotation=45)  # Rotate x-axis labels for better readability\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"PublicationFrequency.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists - no download - :Saved  0 :  Quantum Gravity\n"
     ]
    }
   ],
   "source": [
    "queries = ['abs:PINN AND ti:PINN', \n",
    "            'abs:Physics-Informed Machine Learning AND ti:Physics-Informed Machine Learning', \n",
    "            'abs:Physics-Informed Neural Networks AND ti:Physics Informed Neural Networks', \n",
    "            'abs:PIML AND ti:PIML']\n",
    "\n",
    "cutoffDate = 1990\n",
    "maxNumberOfPapers = 2\n",
    "\n",
    "all_data, names_list, title_list, references = SearchArxiv(queries, maxNumberOfPapers, cutoffDate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(all_data, columns = ['Authors', 'Title', 'Date', 'Summary', 'URL', 'Query']) \n",
    "df = df.sort_values('Date', ascending=False)\n",
    "df.to_excel(\"Overview.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: When  cdn_resources is 'local' jupyter notebook has issues displaying graphics on chrome/safari. Use cdn_resources='in_line' or cdn_resources='remote' if you have issues viewing graphics in a notebook.\n"
     ]
    }
   ],
   "source": [
    "net = createAuthorNetwork(names_list, title_list, df, cutoffDate, 0.5)\n",
    "createDateHistogram(list(df.Date))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "enviroment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
